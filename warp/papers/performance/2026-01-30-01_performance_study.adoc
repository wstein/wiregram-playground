= Performance Considerations for Warp (Crystal)
Werner Stein

include::2026-01-28-01_reference_architecture.adoc[tag=pipeline]
include::2026-01-28-01_reference_architecture.adoc[tag=scenarios]
== Abstract
This paper summarizes the performance techniques currently present in the Warp (Crystal) codebase, evaluates their alignment with the Crystal 1.19 performance guide, and proposes further optimizations with an emphasis on SIMD and low-level tuning. The goal is to balance throughput, correctness, and maintainability on Apple Silicon while keeping the code portable to non-AArch64 targets.

== Background
The project delivers a zero-copy JSON token iterator and a tape-building stage2 parser. Stage1a structural scanning is SIMD-accelerated on AArch64 via NEON inline assembly; when SIMD instructions are unavailable the scalar backend is used as a fallback. Optional x86 SIMD backends (SSE2/AVX/AVX2/AVX512) are used when built with the corresponding flags. Stage1b assembles tokens from scan artifacts. Stage2 remains scalar but leverages precomputed structural indexes from stage1a. The implementation follows Crystal idioms (slices, enums, struct-based results) while adopting low-level techniques inspired by Warp.

== Current Performance Techniques
- NEON stage1a scanning: `src/warp/backend/neon_masks.cr` uses NEON to classify structural characters in 16-byte chunks, minimizing branches and memory traffic.
- ASCII-fast UTF-8 validation: Stage1a validates ASCII blocks via NEON and carries scalar state for multibyte sequences, avoiding rescans (`src/warp/lexer/structural_scan.cr`).
- Zero-copy slices: Tokens and tape records reference the original `Bytes` without copying or unescaping.
- Structural-index–driven stage2: Parsing reuses stage1 indexes to avoid rescanning the byte buffer.
- Preallocation: Tape and context stack are sized from the structural count to reduce allocations and bounds checks.
- Parallel benchmarks: `bin/bench` runs per-file benchmarks concurrently to saturate cores during measurement.
- Formatter paths: Tape-based formatting avoids DOM/CST allocation; CST formatting is reserved for JSONC comment preservation.
- SIMD-assisted DOM escaping: formatter uses backend masks to fast-path strings without escapes.
- SIMD number validation: stage2 number parsing uses SIMD-assisted digit scans to reduce per-byte branching.
- SIMD JSONC scanning: token scanner uses SIMD newline/whitespace detection to skip comments faster.
- SoA view: optional `IR::SoAView` provides columnar tape data for hot scans and benchmarks.

== Measured Throughput
Local release builds with `scripts/benchmark_format.cr` and `--stress-seconds 2 --stress-workers 2` show the following steady-state results (Apple Silicon PoC environment):

* `spec/fixtures/jsonc_example.jsonc`: tape+pretty 48.86 MB/s, dom+pretty 32.17 MB/s, cst+pretty 34.64 MB/s, ast+pretty 26.47 MB/s, tape pretty-only 399.54 MB/s.
* `spec/fixtures/rcl_test.json`: tape+pretty 50.44 MB/s, dom+pretty 27.56 MB/s, cst+pretty 16.62 MB/s, ast+pretty 9.88 MB/s, tape pretty-only 251.00 MB/s.
* `spec/fixtures/twitter.json`: tape+pretty 92.35 MB/s, dom+pretty 47.83 MB/s, cst+pretty 31.01 MB/s, ast+pretty 24.91 MB/s, tape pretty-only 300.50 MB/s.

SoA view overhead remains small: building the view adds ~0.01–2.75 ms across the fixtures, and scan-type passes complete in under 0.26 ms for the largest dataset.

== Alignment with Crystal 1.19 Performance Guide
- Data locality: Uses contiguous `Bytes` and arrays; avoids per-token allocations.
- Avoiding copies: Zero-copy slices and tape records follow the guide’s advice to minimize heap traffic.
- Inlineable hot paths: Small structs/enums and short helper methods are suitable for inlining, though explicit `@[AlwaysInline]` is not yet applied.
- Concurrency: Fiber-based parallelism in the benchmark harness matches Crystal’s lightweight concurrency model.
- Unsafe optimizations: Limited use of `unsafe` today; further gains are possible by removing redundant bounds checks as allowed by structural guarantees.

== Opportunities for Further Optimization
=== SIMD and Parsing
- Full NEON UTF-8 validation (multibyte): Extend SIMD beyond the ASCII fast-path by classifying lead bytes, counting expected continuations, and carrying state across blocks to eliminate scalar fallback on mixed text.
- SIMD string end scan: Use NEON to locate quotes/backslashes within bounded regions defined by structural indexes, reducing scalar scans for string termination.
- SIMD whitespace/colon/comma scan in stage2: Reuse structural indexes to bypass scalar whitespace trimming and detect delimiters with small NEON masks.
- SIMD block-comment scanning: add masks for `*` and `/` to accelerate JSONC block comment termination.

=== Scalar Tightening
- Inline hot helpers: Apply `@[AlwaysInline]` to tiny functions (`scalar_type`, iterator accessors) and inline tape-building helpers to reduce call overhead.
- Bounds-check minimization: Replace repeated safe indexing with `unsafe_fetch` inside guarded hot loops where structural indexes guarantee safety.
- Stack/tape reuse: Reuse preallocated tape and context arrays per parser instance to lower GC pressure across parses.
- Simplified fast paths: Split common object/array cases (value + comma/end) into branch-light paths once correctness is restored.

=== Build and Tooling
- Benchmark flags: Use `crystal build bin/bench.cr --release -O3 --no-debug` and a fast `CRYSTAL_CACHE_DIR` to keep measurement noise low.
- Verification toggles: Keep debug-only cross-checks (e.g., `WARP_VERIFY_NEON`) off in production builds to avoid overhead.

== Proposed Work Plan
[cols="2,4,3,3",options="header"]
|===
| Area | Action | Expected Benefit | Risk/Notes
| UTF-8 | Implement full NEON multibyte validator with carried state | Major: reduces scalar fallback on text-heavy JSON | Requires careful state handling and tests
| Strings | NEON quote/backslash scan bounded by structurals | Moderate: faster string termination | Must preserve escape correctness
| Stage2 | SIMD colon/comma/whitespace scan | Moderate: fewer scalar scans | Keep logic aligned with stage1 indexes
| JSONC | SIMD block-comment termination scan | Small/Moderate: faster comment parsing | Ensure CRLF handling and `*/` detection
| Tape | SoA view for scan-heavy paths | Moderate: faster scans, better cache locality | Keep AoS canonical to avoid refactors
| Inlining/unsafe | `@[AlwaysInline]`, guarded `unsafe_fetch` in hot loops | Moderate: lower overhead, fewer bounds checks | Validate with benchmarks; watch code size
| Buffers | Reuse tape/stack between parses | Small: reduced GC churn | Parser becomes stateful; add reset
| Fast paths | Restore and simplify object/array common-case branches | Moderate: fewer branches | Only after current TapeError is resolved
|===

== Conclusion
The codebase already follows several best practices from the Crystal performance guide: SIMD acceleration, zero-copy slices, structural-index reuse, and preallocation. The largest remaining wins likely come from a complete SIMD UTF-8 path, SIMD-assisted string/delimiter scanning, and selective inlining/bounds-check removal. Correctness in stage2 must be reestablished before adopting aggressive fast paths. With these steps, the parser can approach the throughput of native Warp while preserving Crystal ergonomics.
